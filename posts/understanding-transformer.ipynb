{
 "cells": [
  {
   "cell_type": "raw",
   "id": "9690a3c6-69f5-4eab-a416-725cdcaf97ed",
   "metadata": {},
   "source": [
    "---\n",
    "title: TransformerãŒä½•ã‚’ã‚„ã£ã¦ã„ã‚‹ã®ã‹ç†è§£ã™ã‚‹\n",
    "date: 28/04/2023\n",
    "categories: [ja, NLP, deep]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecfbeb3-8521-4f34-8080-7cfbcf028edb",
   "metadata": {},
   "source": [
    "ChatGPTãŒå¤§ãƒã‚ºãƒªã—ã¦ã„ã‚‹æ˜¨ä»Šã§ã™ã€‚åƒ•ã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è€ƒãˆã‚‹ã®ãŒé¢å€’ãªã®ã§ï¼ˆãˆãˆ...)ã‚ã¾ã‚Šä½¿ã‚ãªã„ã®ã§ã™ãŒã€å‹äººãŒè«–æ–‡ã‚’æ›¸ãã®ã«ä½¿ã£ã¦ã„ãŸã‚Šã€åƒ•ã®æ¯è¦ªãŒè©±ã—ç›¸æ‰‹ã«ä½¿ã£ã¦ã„ãŸã‚Šã™ã‚‹ã‚ˆã†ã§ã™ã€‚è¦ªä¸å­ãªæ¯å­ã§ã”ã‚ã‚“ãªã•ã„ã¨ã„ã†æ„Ÿã˜ã‚‚ã—ã¾ã™ãŒã€åƒ•ã¯ã„ã¾ã ã«TransformerãŒä½•ãªã®ã‹ã™ã‚‰ã‚ˆãã‚ã‹ã£ã¦ã„ãªã„ã§ã€ã“ã‚Œã‚’æ©Ÿã«ä½•ã‚’ã‚„ã£ã¦ã„ã‚‹ã®ã‹ãã‚‰ã„ã¯ç†è§£ã—ã¦ã¿ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d724c74d-6ac1-463e-b6e7-847b66b1aaeb",
   "metadata": {},
   "source": [
    "# å‚è€ƒã«ã—ãŸã‚‚ã®\n",
    "- [Formal Algorithms for Transformers](https://arxiv.org/abs/2207.09238)\n",
    "  - ç–‘ä¼¼ã‚³ãƒ¼ãƒ‰ã‚’ã¾ã¨ã‚ãŸè«–æ–‡ã§ã™ã€‚ã“ã‚ŒãŒä¸€ç•ªã‚ã‹ã‚Šã‚„ã™ã„ã¨æ€ã†ã®ã§ã€ã¨ã‚Šã‚ãˆãšã“ã‚Œã‚’è¦‹ã‚Œã°ã„ã„ã¨æ€ã„ã¾ã™ã€‚ä»–ã«ã‚‚[The Illustrated GPT-2](https://jalammar.github.io/illustrated-gpt2/)ãªã©ã‚’è¦‹ãŸã®ã§ã™ãŒã€ã‚ˆãã‚ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n",
    "- [Shumi-Note Transformer](https://github.com/syuntoku14/Shumi-Note/blob/main/notebooks/NN_transformer.ipynb)\n",
    "  - ã“ã‚Œã‚’è¦‹ã¦çœŸä¼¼ã—ã‚ˆã†ã¨æ€ã£ãŸã®ãŒã“ã®è¨˜äº‹ã®ãã£ã‹ã‘ã§ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f645938a-ee71-4bec-a32f-933a8e243059",
   "metadata": {},
   "source": [
    "# ãƒˆãƒ¼ã‚¯ãƒ³åˆ—ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°\n",
    "Transformerã§ã¯ã€å…¥åŠ›ã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³åˆ—ã«å¯¾ã—ã€multihead attentionã¨å‘¼ã°ã‚Œã‚‹ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’ç¹°ã‚Šè¿”ã—é©ç”¨ã—ã¾ã™ã€‚ãã“ã§ã€ã¾ãšã©ã®ã‚ˆã†ã«ãƒˆãƒ¼ã‚¯ãƒ³åˆ—ã‚’ãƒ™ã‚¯ãƒˆãƒ«ã«å°„å½±ã™ã‚‹ã®ã‹ã‚’èª¬æ˜ã—ã¾ã™ã€‚\n",
    "\n",
    "## æœ€åˆã«åˆ—ãŒã‚ã£ãŸ\n",
    "ãƒˆãƒ¼ã‚¯ãƒ³åˆ—ã¨ã„ã†ã®ã¯æ–‡å­—é€šã‚Šãƒˆãƒ¼ã‚¯ãƒ³ã‹ã‚‰ãªã‚‹åˆ—ã®ã“ã¨ã§ã™ã€‚ãƒˆãƒ¼ã‚¯ãƒ³ã¯æœ‰é™é›†åˆã®è¦ç´ ã§ã™ã€‚å®Ÿç”¨ä¸Šã¯byte pair encodingã«ã‚ˆã‚Šå¾—ã‚‰ã‚ŒãŸsubwordãªã©ãŒã“ã‚Œã«è©²å½“ã—ã¾ã™ãŒã€ã¨ã‚Šã‚ãˆãšæ°—ã«ã—ãªãã¦ã„ã„ã§ã™ã€‚ãƒˆãƒ¼ã‚¯ãƒ³ã®é›†åˆã‚’$V$ã¨ã—ã€$[Nv] := {1, ..., Nv}$ã¨ç•ªå·ä»˜ã‘ã—ã¦ãŠãã¾ã™ã€‚ãƒˆãƒ¼ã‚¯ãƒ³åˆ—ã‚’$x = x[1: l]$ã¨æ›¸ãã¾ã™ã€‚ã¾ãŸã€ãƒˆãƒ¼ã‚¯ãƒ³åˆ—ã®æœ€å¤§ã®é•·ã•ã‚’$L$ã¨ã—ã¾ã™ã€‚ãƒˆãƒ¼ã‚¯ãƒ³ã¨ã—ã¦é€£ç¶šå€¤ã‚„ç„¡é™é›†åˆã¯æ‰±ãˆãªã„ã¨æ€ã„ã¾ã™ãŒã€ç´ äººãªã®ã§ä½•ã‹æŠœã‘é“ãŒã‚ã‚‹ã‹ã©ã†ã‹ã¯çŸ¥ã‚Šã¾ã›ã‚“ã€‚\n",
    "\n",
    "## ãƒˆãƒ¼ã‚¯ãƒ³ã‹ã‚‰ãƒ™ã‚¯ãƒˆãƒ«ã«\n",
    "é©å½“ãª$d_e \\times Nv$æ¬¡å…ƒã®è¡Œåˆ—$W_e$ã‚’ä½¿ã£ã¦ã€$v$ç•ªç›®ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‹ã‚‰åŸ‹ã‚è¾¼ã¿ï¼ˆToken embeddingï¼‰ã‚’ $e = W_e[:, v]$ã«ã‚ˆã‚Šå¾—ã¾ã™ã€‚ã“ã‚Œã¯$d_e$æ¬¡å…ƒã®ãƒ™ã‚¯ãƒˆãƒ«ã«ãªã‚Šã¾ã™ã€‚ãªãŠã€numpyé¢¨ã«$i$ç•ªç›®ã®è¡Œãƒ™ã‚¯ãƒˆãƒ«ã‚’$W[i, :]$ã€$j$ç•ªç›®ã®åˆ—ãƒ™ã‚¯ãƒˆãƒ«ã‚’$W[:, j]$ã¨æ›¸ã„ã¦ã„ã¾ã™ã€‚ã“ã®è¡Œåˆ—$W_e$ã¯å‹¾é…é™ä¸‹ã«ã‚ˆã‚Šå­¦ç¿’ã•ã‚Œã‚‹ã‚ˆã†ã§ã™ã€‚\n",
    "\n",
    "## ã¤ã„ã§ã«ä½ç½®ã‚‚ãƒ™ã‚¯ãƒˆãƒ«ã«\n",
    "é©å½“ãª$d_p \\times L$æ¬¡å…ƒã®è¡Œåˆ—$W_p$ã‚’ä½¿ã£ã¦ã€ãƒˆãƒ¼ã‚¯ãƒ³åˆ—ä¸­ã®$l$ç•ªç›®ã«ãƒˆãƒ¼ã‚¯ãƒ³ãŒã‚ã‚‹ã¨ã„ã†æƒ…å ±ã‹ã‚‰ã€ä½ç½®åŸ‹ã‚è¾¼ã¿ï¼ˆPositional embeddingï¼‰ã‚’ $p = W_p[:, l]$ã«ã‚ˆã‚Šå¾—ã¾ã™ã€‚ã“ã‚Œã‚‚$d_e$æ¬¡å…ƒã®ãƒ™ã‚¯ãƒˆãƒ«ã«ãªã‚Šã¾ã™ã€‚æ­£ç›´ãªã‚“ã®æ„å‘³ãŒã‚ã‚‹ã®ã‹ã‚ˆãã‚ã‹ã‚‰ãªã„ã®ã§ã™ãŒã€ã“ã‚Œã‚’å…ˆç¨‹ã®ãƒˆãƒ¼ã‚¯ãƒ³åŸ‹ã‚è¾¼ã¿ã«è¶³ã—ã¦ãƒˆãƒ¼ã‚¯ãƒ³åˆ—$x$ã®$t$ç•ªç›®ã®ãƒˆãƒ¼ã‚¯ãƒ³$x[t]$ã«å¯¾ã™ã‚‹åŸ‹ã‚è¾¼ã¿ã‚’$e = W_e[:, x[t]] + W_p[:, t]$ã«ã‚ˆã£ã¦å¾—ã¾ã™ã€‚ã“ã‚Œè¶³ã—ã¦å¤§ä¸ˆå¤«ãªã®ã‹ãªï¼Ÿã£ã¦æ€ã†ã‚“ã§ã™ãŒã€‚\n",
    "ä½ç½®åŸ‹ã‚è¾¼ã¿ã¯ã€å­¦ç¿’ã•ã‚Œã‚‹ã“ã¨ã‚‚ã‚ã‚‹ã‚ˆã†ã§ã™ãŒã€TransformerãŒæœ€åˆã«ææ¡ˆã•ã‚ŒãŸ[Attention Is All You Need](https://arxiv.org/abs/1706.03762)ã®è«–æ–‡ã§ã¯ã€ä»¥ä¸‹ã®ã‚ˆã†ã«æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚\n",
    "$$\n",
    "\\begin{align*}\n",
    "W_p[2i - 1, t] &= \\sin (\\frac{t}{L^{2i / d_e}}) \\\\\n",
    "W_p[2i, t] &= \\cos (\\frac{t}{L^{2i / d_e}}) \\\\\n",
    "&~~~~~(0 < 2i \\leq d_e)\n",
    "\\end{align*}\n",
    "$$\n",
    "ã“ã‚Œã‚’$L=50, d_e = 5$ã¨ã—ã¦å¯è¦–åŒ–ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef87949-a62c-4e0f-a139-11753389e2c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "L = 50\n",
    "d_e = 5\n",
    "x = np.arange(L)\n",
    "for i in range(1, 1 + d_e):\n",
    "    if i % 2 == 0:\n",
    "        w_p = np.sin(x / L ** (i / d_e))\n",
    "    else:\n",
    "        w_p = np.cos(x / L ** ((i - 1) / d_e)) \n",
    "    _ = plt.plot(x, w_p, label=f\"i={i}\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc464505-a4d0-4b3b-86f0-3cf0fcc333ea",
   "metadata": {},
   "source": [
    "ã¨ã„ã†ã‚ã‘ã§ã€ã“ã®åŸ‹ã‚ã“ã¿ã¯å„æˆåˆ†ã”ã¨ã«ç•°ãªã‚‹å‘¨æ³¢æ•°ã§ã®å˜èªã‚’åŸ‹ã‚è¾¼ã‚€ã‚ˆã†ã§ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€çŸ­ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ä¸­ã§ã®ä½ç½®ã‚‚åŒæ™‚ã«è€ƒæ…®ã§ãã‚‹ã®ã‹ãªã€‚\n",
    "\n",
    "# Attention\n",
    "Transformerã®ä¸»è¦ãªæ§‹æˆè¦ç´ ã«ãªã‚‹ã®ãŒAttentionã§ã™ã€‚Attentionã§ã¯ã€å…¥åŠ›ã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³åˆ—ä¸­ã®ã™ã¹ã¦ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®çµ„ã¿åˆã‚ã›ã«ã¤ã„ã¦ã€ãã„ã¤ã‚‰ã®çµ„ã¿åˆã‚ã›ãŒã©ã‚Œãã‚‰ã„é‡è¦ãªã®ã‹ã¨ã„ã†ãƒ¢ãƒ‡ãƒ«åŒ–ã‚’è¡Œã„ã¾ã™ã€‚å…·ä½“çš„ã«ã€å˜ä¸€ã‚¯ã‚¨ãƒªã«å¯¾ã™ã‚‹Attentionã§ã¯ã€ç¾åœ¨ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‹ã‚‰å¾—ãŸåŸ‹ã‚è¾¼ã¿$e_t$ã¨$x$ä¸­ã®ã™ã¹ã¦ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®åŸ‹ã‚è¾¼ã¿$e_0, e_1, ..., e_{Nv} \\in E$ã«å¯¾ã—ã€ä»¥ä¸‹ã®ã‚ˆã†ãªæ“ä½œã‚’è¡Œã„ã¾ã™ã€‚\n",
    "$$\n",
    "\\begin{align*}\n",
    "q_t &\\leftarrow W_q e_t + b_q \\\\\n",
    "k_{t'} &\\leftarrow W_k e_{t'} + b_k,~\\forall e_{t'} \\in E \\\\\n",
    "v_{t'} &\\leftarrow W_v e_{t'} + b_v,~\\forall e_{t'} \\in E \\\\\n",
    "\\alpha_{t'} &\\leftarrow \\frac{\\exp(q_t^\\top k_{t'} / \\sqrt{d_{\\textrm{attn}}})}{\\sum_u \\exp(q_t^\\top k_{t'} / \\sqrt{d_{\\textrm{attn}}})},~\\forall e_{t'} \\in E \\\\\n",
    "v_\\textrm{attr} &\\leftarrow \\sum_{t = 1}^T \\alpha_{t'} v_{t'}\n",
    "\\end{align*}\n",
    "$$\n",
    "åŸ‹ã‚è¾¼ã¿ã®æ¬¡å…ƒã‚’$d_\\textrm{in}$ã€å‡ºåŠ›ã®æ¬¡å…ƒã¨$d_\\textrm{out}$ã¨ã™ã‚‹ã¨ã€$W_q, Q_k$ã¯$d_\\textrm{attn} \\times e$ã®è¡Œåˆ—ã€$W_q, Q_k$ã¯$d_\\textrm{out} \\times d_\\textrm{in}$ã®è¡Œåˆ—ã€$b_*$ã¯ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆãƒã‚¤ã‚¢ã‚¹é …ï¼‰ã§ã™ã€‚ã“ã“ã§ã€$q^\\top k_{t'}$ã®å€¤ã§ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹ã‚’ã¨ã£ã¦$v$ã«ãƒã‚¹ã‚¯ã‚’ã‹ã‘ã‚‹ã®ã§ã€ã“ã‚Œã¯ç¾åœ¨ã®ãƒˆãƒ¼ã‚¯ãƒ³ã¨$t'$ç•ªç›®ã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒã€Œã©ã‚Œãã‚‰ã„å¯¾å¿œã—ã¦ã„ã‚‹ã‹ã€ã‚’è¡¨ã—ã¦ã„ã¦ã»ã—ã„ã§ã™ã€‚$v_{t'}$ãŒä½•ã‚’è¡¨ã—ã¦ã„ã‚‹ã‹ã¯ã‚¿ã‚¹ã‚¯ã«ã‚ˆã£ã¦ç•°ãªã‚‹ã¨æ€ã„ã¾ã™ãŒã€$t'$ç•ªç›®ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®åŸ‹ã‚è¾¼ã¿ã«ç·šå½¢ã«é–¢ä¿‚ã™ã‚‹å€¤ãŒå…¥ã£ã¦ã„ã‚‹ã¯ãšã§ã™ã€‚ã“ã®ãƒˆãƒ¼ã‚¯ãƒ³åˆ—ã«å¾Œã‚å‘ãã®å› æœé–¢ä¿‚ãŒãªã„å ´åˆï¼ˆã‚ã‚‹ãƒˆãƒ¼ã‚¯ãƒ³$x[t]$ãŒã€ä»»æ„ã®æœªæ¥ã®ãƒˆãƒ¼ã‚¯ãƒ³$x[t']~\\textrm{where}~t < t'$ã«ä¾å­˜ã—ãªã„å ´åˆï¼‰ã¯ã€$\\alpha_{t'}$ã«ãƒã‚¹ã‚¯ã‚’ã‹ã‘ã‚‹($\\alpha_{t'}[i] = 0 ~\\textrm{if}~t < i$)ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã€‚ãªã®ã§ã€æœªæ¥ã‚’äºˆæ¸¬ã™ã‚‹éš›ã«ã¯ã“ã®ãƒã‚¹ã‚¯ã‚’ã‹ã‘ã‚‹ã®ãŒä¸€èˆ¬çš„ãªã‚ˆã†ã§ã™ã€‚\n",
    "\n",
    "å®Ÿéš›ã«ã€æ™‚ç³»åˆ—ã‹ã‚‰ä½•ã‹ï¼ˆæ¬¡ã®å˜èªã€ãƒ©ãƒ™ãƒ«ãªã©ï¼‰ã‚’äºˆæ¸¬ã™ã‚‹éš›ã«ã¯ã€ã“ã®å˜ä¸€ã‚¯ã‚¨ãƒªã«å¯¾ã™ã‚‹Attentionã‚’é•·ã•$T$ã®ç³»åˆ—å†…ã®ã™ã¹ã¦ã®ãƒˆãƒ¼ã‚¯ãƒ³ã«å¯¾ã—ã¦è¨ˆç®—ã—ã€$d_\\textrm{out} \\times T$ã®è¡Œåˆ—$\\tilde{V}$ã‚’å¾—ã¾ã™ã€‚\n",
    "\n",
    "ã¨ã‚Šã‚ãˆãšã“ã‚Œã‚’å­¦ç¿’ã•ã›ã¦ã¿ã¾ã—ã‚‡ã†ã€‚ä»Šå›ã¯[jax](https://jax.readthedocs.io/en/latest/)ã¨[equinox](https://docs.kidger.site/equinox/)ã‚’ä½¿ã£ã¦ãƒ¢ãƒ‡ãƒ«ã‚’æ›¸ã„ã¦ã¿ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb9e788-b0b0-4ae6-b671-ed8c1b23876c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import equinox as eqx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "class Attention(eqx.Module):\n",
    "    w_q: jax.Array\n",
    "    b_q: jax.Array\n",
    "    w_k: jax.Array\n",
    "    b_k: jax.Array\n",
    "    w_v: jax.Array\n",
    "    b_v: jax.Array\n",
    "    sqrt_d_attn: float\n",
    "\n",
    "    def __init__(self, d_in: int, d_attn: int, d_out: int, key: jax.Array) -> None:\n",
    "        wq_key, bq_key, wk_key, bk_key, wv_key, bv_key = jax.random.split(key, 6)\n",
    "        self.w_q = jax.random.normal(wq_key, (d_attn, d_in))\n",
    "        self.b_q = jax.random.normal(bq_key, (d_attn, 1))\n",
    "        self.w_k = jax.random.normal(wk_key, (d_attn, d_in))\n",
    "        self.b_k = jax.random.normal(bk_key, (d_attn, 1))\n",
    "        self.w_v = jax.random.normal(wv_key, (d_out, d_in))\n",
    "        self.b_v = jax.random.normal(bv_key, (d_out, 1))\n",
    "        self.sqrt_d_attn = float(np.sqrt(d_attn))\n",
    "\n",
    "    def __call__(self, e: jax.Array) -> jax.Array:\n",
    "        \"\"\"Take a matrix e with shape [d_in x seq_len], compute attention for all tokens in e.\n",
    "        Outputs a matrix with shape [d_out x seq_len]\n",
    "        \"\"\"\n",
    "        q = self.w_q @ e + self.b_q\n",
    "        k = self.w_k @ e + self.b_k\n",
    "        v = self.w_v @ e + self.b_v\n",
    "        alpha = jax.nn.softmax(q.T @ k / self.sqrt_d_attn, axis=-1)\n",
    "        return v @ alpha.T\n",
    "\n",
    "\n",
    "def causal_mask(x: jax.Array) -> jax.Array:\n",
    "    ltri = jnp.tri(x.shape[0], dtype=bool, k=-1)\n",
    "    return jax.lax.select(ltri, jnp.ones_like(x) * -jnp.inf, x)\n",
    "\n",
    "\n",
    "class MaskedAttention(Attention):\n",
    "    def __call__(self, e: jax.Array) -> jax.Array:\n",
    "        q = self.w_q @ e + self.b_q\n",
    "        k = self.w_k @ e + self.b_k\n",
    "        v = self.w_v @ e + self.b_v\n",
    "        score = causal_mask(q.T @ k) / self.sqrt_d_attn\n",
    "        alpha = jax.nn.softmax(score, axis=-1)\n",
    "        return v @ alpha.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eba767b-c7c9-4fe2-a1f5-8a3cf6fcf263",
   "metadata": {},
   "source": [
    "ã“ã‚Œã‚’å­¦ç¿’ã•ã›ã¦ã¿ã¾ã—ã‚‡ã†ã€‚ãƒˆãƒ¼ã‚¯ãƒ³ã¨ã—ã¦ã€å¤©æ°—ğŸŒ§ï¸ãƒ»â˜ï¸ãƒ»â˜€ï¸ã‚’è€ƒãˆã¾ã™ã€‚ã“ã®3ã¤ã®è¨˜å·ã«å¯¾ã—é©å½“ãªåŸ‹ã‚è¾¼ã¿ã‚’ä¸ãˆã¦ã€æ¬¡ã®æ—¥ã®å¤©æ°—ã‚’å­¦ç¿’ã•ã›ã¦ã¿ã¾ã™ã€‚ã‚ˆãã‚ã‹ã‚‰ãªã„ã®ã§ã€ãƒ€ãƒ–ã‚‰ãªã„ã‚ˆã†ã«ãƒˆãƒ¼ã‚¯ãƒ³åŸ‹ã‚è¾¼ã¿ã‚’$[-1, 0, 1]$ã€ä½ç½®åŸ‹ã‚è¾¼ã¿ã‚’$1 / t$ã¨ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚æœ€å¤§æ–‡å­—åˆ—é•·ã¯é©å½“ã«10ã«ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab8ccf5-bbd0-4d20-8324-a5254ef9df57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOKEN_EMBEDDING = {\n",
    "    \"ğŸŒ§ï¸\": -1.0,\n",
    "    \"â˜ï¸\": 0.0,\n",
    "    \"â˜€ï¸\": 1.0,\n",
    "}\n",
    "\n",
    "def get_embedding(seq: str, max_seq_len: int | None = None) -> np.ndarray:\n",
    "    if max_seq_len is None:\n",
    "        max_seq_len = len(seq)\n",
    "    length = len(seq) // 2\n",
    "    e = np.zeros(length)\n",
    "    for i in range(length):\n",
    "        x = seq[i * 2: i * 2 + 2]\n",
    "        e[i] = TOKEN_EMBEDDING[x] + (i + 1) / max_seq_len\n",
    "    return e.reshape(1, length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fac285c-fae4-4cd9-a1e0-a2dea1179670",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Markovãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’\n",
    "\n",
    "ã¾ãšç°¡å˜ãªãƒ¢ãƒ‡ãƒ«ã§å¤©æ°—ã‚’ç”Ÿæˆã—ã¦ã¿ã¾ã™ã€‚**æ¬¡ã®æ—¥ã®å¤©æ°—ã¯ã€å‰ã®æ—¥ã®å¤©æ°—ã«ã‚‚ã¨ã¥ã„ã¦ç¢ºç‡çš„ã«æ±ºã¾ã‚‹**ã“ã¨ã«ã—ã¾ã—ã‚‡ã†ã€‚ğŸŒ§ï¸ãƒ»â˜ï¸ãƒ»â˜€ï¸ãŒãƒãƒ«ãƒãƒã‚¤ãƒˆæ–‡å­—ã§ã‚ã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ã€ä»¥ä¸‹ã®ã‚ˆã†ã«å®Ÿè£…ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c945d0e4-fb80-49b1-bdcf-e9c5eb9245c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "\n",
    "_GEN = np.random.Generator(np.random.PCG64(11111))\n",
    "_MARKOV = {\n",
    "    \"\": [0.3, 0.4, 0.3],\n",
    "    \"ğŸŒ§ï¸\": [0.6, 0.3, 0.1],\n",
    "    \"â˜ï¸\": [0.3, 0.4, 0.3],\n",
    "    \"â˜€ï¸\": [0.2, 0.3, 0.5],\n",
    "}\n",
    "\n",
    "WEATHERS = [\"ğŸŒ§ï¸\", \"â˜ï¸\", \"â˜€ï¸\"]\n",
    "\n",
    "\n",
    "def markov(prev: str) -> str:\n",
    "    prob = _MARKOV[prev[-2:]]\n",
    "    return prev + _GEN.choice(WEATHERS, p=prob)\n",
    "\n",
    "\n",
    "def generate(f, n: int):\n",
    "    value = \"\"\n",
    "    for _ in range(n):\n",
    "        value = f(value)\n",
    "    return value\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class Dataset:\n",
    "    weathers: list[str]\n",
    "    embeddings: jax.Array\n",
    "    next_weather_indices: jax.Array\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.weathers)\n",
    "\n",
    "\n",
    "def make_dataset(f, seq_len, size) -> Dataset:\n",
    "    w_list, e_list, nw_list = [], [], []\n",
    "    for _ in range(size):\n",
    "        weathers = generate(f, seq_len + 1)\n",
    "        e = jnp.array(get_embedding(weathers[:-2]))\n",
    "        w_list.append(weathers)\n",
    "        e_list.append(e)\n",
    "        nw_list.append(WEATHERS.index(weathers[-2:]))\n",
    "    return Dataset(w_list, jnp.stack(e_list), jnp.array(nw_list))\n",
    "\n",
    "\n",
    "generate(markov, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03961817-2903-4643-9009-b65a8285cb3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "ã“ã‚“ãªæ„Ÿã˜ã§ã™ã€‚ã„ã¾ã€æ¬¡ã®æ—¥ã®å¤©æ°—ã ã‘äºˆæ¸¬ã—ãŸã„ã®ã§ã€ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã¯é›†åˆ{ğŸŒ§ï¸ãƒ»â˜ï¸ãƒ»â˜€ï¸}ä¸Šã§ã®ç¢ºç‡åˆ†å¸ƒãŒé©åˆ‡ã§ã—ã‚‡ã†ã€‚Attentionã¯é•·ã•$T$ã®åŸ‹ã‚è¾¼ã¿åˆ—ã«å¯¾ã—ã¦é•·ã•$d_\\textrm{out} \\times T$ã®è¡Œåˆ—ã‚’ã‹ãˆã—ã¾ã™ã€‚ãªã®ã§ã€$d_\\textrm{out} = 3$ã¨ã—ã€Attentionã®å‡ºåŠ›$\\tilde{V}$ã«å¯¾ã—ã¦ã‚½ãƒ•ãƒˆãƒãƒƒã‚¯ã‚¹é–¢æ•°ã‚’é©ç”¨ã—ã€$P_t = \\textrm{softmax}(\\tilde{V}[:, t])$ã¨ã—ã¾ã™ã€‚ã“ã®ã¨ãã€$P_t$ã®å„è¦ç´ ãŒæ¬¡ã®æ—¥ğŸŒ§ï¸ãƒ»â˜ï¸ãƒ»â˜€ï¸ã«ãªã‚‹ç¢ºç‡ã‚’è¡¨ã™ã¨ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«åŒ–ã—ã¾ã™ã€‚ã“ã‚Œã‚’ã€å¯¾æ•°å°¤åº¦ã®å’Œ$\\sum_t \\log P_t(\\textrm{next weather})$ã‚’æœ€å¤§åŒ–ã™ã‚‹ã‚ˆã†ã«å­¦ç¿’ã—ã¾ã—ã‚‡ã†ã€‚å­¦ç¿’ã®ã‚³ãƒ¼ãƒ‰ã‚’å®šç¾©ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf1d94d-da0b-4e5e-9009-122584989969",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optax\n",
    "\n",
    "\n",
    "def neg_logp(model: eqx.Module, seq: jax.Array, next_w: jax.Array) -> jax.Array:\n",
    "    batch_size = seq.shape[0]\n",
    "    tilde_v = jax.vmap(model)(seq)  # B x OUT x SEQ_LEN\n",
    "    logp = jax.nn.log_softmax(tilde_v, axis=1)  # B x OUT x SEQ_LEN\n",
    "    logp_masked = logp * jax.nn.one_hot(next_w, num_classes=3).reshape(-1, 3, 1)\n",
    "    return -jnp.mean(jnp.sum(logp_masked.reshape(batch_size, -1), axis=-1))\n",
    "\n",
    "\n",
    "compute_loss = eqx.filter_value_and_grad(neg_logp)\n",
    "evaluate_model = jax.jit(neg_logp)\n",
    "\n",
    "\n",
    "def train(\n",
    "    n_epochs: int,\n",
    "    minibatch_size: int,\n",
    "    model: eqx.Module,\n",
    "    ds: Dataset,\n",
    "    test_ds: Dataset,\n",
    "    key: jax.Array,\n",
    "    learning_rate: float = 1e-2,\n",
    ") -> tuple[eqx.Module, jax.Array, list[float], list[float]]:\n",
    "    n_data = len(ds)\n",
    "    indices = jnp.arange(n_data)\n",
    "    optim = optax.adam(learning_rate)\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def train_1step(\n",
    "        model: eqx.Module,\n",
    "        seq: jax.Array,\n",
    "        next_w: jax.Array,\n",
    "        opt_state: optax.OptState,\n",
    "    ) -> tuple[jax.Array, eqx.Module, optax.OptState]:\n",
    "        loss, grads = compute_loss(model, seq, next_w)\n",
    "        updates, opt_state = optim.update(grads, opt_state)\n",
    "        model = eqx.apply_updates(model, updates)\n",
    "        return loss, model, opt_state\n",
    "\n",
    "    opt_state = optim.init(model)\n",
    "    n_optim_epochs = n_data // minibatch_size\n",
    "    loss_list, eval_list = [], []\n",
    "    for epoch in range(n_epochs):\n",
    "        key, shuffle_key = jax.random.split(key)\n",
    "        shuffled_indices = jax.random.shuffle(shuffle_key, indices)\n",
    "        for _ in range(n_optim_epochs):\n",
    "            e = ds.embeddings[shuffled_indices]\n",
    "            next_w = ds.next_weather_indices[shuffled_indices]\n",
    "            loss, model, opt_state = train_1step(model, e, next_w, opt_state)\n",
    "            loss_list.append(loss.item())\n",
    "            test_loss = evaluate_model(\n",
    "                model, test_ds.embeddings, test_ds.next_weather_indices\n",
    "            )\n",
    "            eval_list.append(test_loss.item())\n",
    "    return model, key, loss_list, eval_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481f39a1-3cb7-4526-893e-effff5c36e48",
   "metadata": {
    "tags": []
   },
   "source": [
    "ã“ã‚Œã‚’å®Ÿéš›ã«èµ°ã‚‰ã›ã¦ã¿ã¾ã™ã€‚é©å½“ã«ã€Attentionã®æ¬¡å…ƒã‚’8ã€å¤©æ°—åˆ—ã®é•·ã•ã‚’10ã«ã—ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793558de-6389-44b2-9982-da31c66f8688",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "D_ATTN = 8\n",
    "SEQ_LEN = 10\n",
    "key = jax.random.PRNGKey(123)\n",
    "model = MaskedAttention(1, D_ATTN, 3, key)\n",
    "ds = make_dataset(markov, SEQ_LEN, 1000)\n",
    "test_ds = make_dataset(markov, SEQ_LEN, 100)\n",
    "model, key, loss_list, eval_list = train(50, 100, model, ds, test_ds, key, 1e-3)\n",
    "plt.plot(loss_list, label=\"Training Loss\")\n",
    "plt.plot(eval_list, label=\"Test Loss\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Negative Log Likelihood\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde21f3a-a9cd-4fc6-ac72-04df8356f913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlog2",
   "language": "python",
   "name": "rlog2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
