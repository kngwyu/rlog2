{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ddf4bb6d-9471-409d-af73-74ab322dde7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "title: Try NWB\n",
    "date: 05/22/2023\n",
    "categories: [en, Neuroscience]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b72d34-2e0f-4eac-853a-223b5b748386",
   "metadata": {},
   "source": [
    "[NWB (Neurodata Without Borders)](https://www.nwb.org/) is a data format proposed to become a data standard for neurophysiology. In this blog post, I'll try to use it and demonstorate how to load the data and to work on the data.\n",
    "\n",
    "# Download the data\n",
    "\n",
    "Here, I try to download the data used in the paper titled [Neurons detect cognitive boundaries to structure episodic memories in humans](https://www.nature.com/articles/s41593-022-01020-w). I didn't have the strong reason to choose it... I just thought human data is more familiar to me than some other animal data. In this paper, the authors say:\n",
    "\n",
    "> We recorded single-neuron activity from individuals with drug-resistant epilepsy implanted with depth electrodes while testing their memory for the content of video clips with two kinds of embedded cognitive boundaries: soft boundaries (SBs) and hard boundaries (HBs). SBs are episodic transitions between related events within the same movie, while HBs are episodic transitions between two unrelated movies.\n",
    "\n",
    "So their participants are already implanted with electrodes, and they measured participant's neural activity during watching some videos they provided. The group of video clips have two categories: soft and hard boundary. The video set with soft boundary has video clips only from the same movie, and the video set with hard boundary has video clips from several random movies. I don't know how these setups matter, but let's see the data. We can find lots of open NWB data (319 now) on [dandi archive](https://dandiarchive.org/). We can download dandi data from the [web page](https://dandiarchive.org/dandiset/000207/) directly or using the [CLI](https://dandi.readthedocs.io/en/latest/) that you can download from PyPI. Here I use the Python API packed with the CLU instead, because this post is entirely written on a Jupyter notebook..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b01741c4-9387-43aa-8e25-4f5980298c25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pynwb\n",
    "from dandi.download import download as dandi_download\n",
    "from matplotlib import pyplot as plt\n",
    "from nwbwidgets import nwb2widget\n",
    "\n",
    "DATA_DIR = Path(\"../data/nwb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72454595-c1cc-47a1-8a8b-8e0068651ccd",
   "metadata": {},
   "source": [
    "Let's download data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c76eed72-8145-48f5-b9ae-5cef08b943ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATH                                          SIZE     DONE            DONE% CHECKSUM STATUS          MESSAGE   \n",
      "000207/dandiset.yaml                                                                  done            updated   \n",
      "000207/sub-16/sub-16_ses-16_ecephys+image.nwb 2.7 MB   2.7 MB           100%    ok    done                      \n",
      "000207/sub-11/sub-11_ses-11_ecephys+image.nwb 1.4 MB   1.4 MB           100%    ok    done                      \n",
      "000207/sub-1/sub-1_ses-1_ecephys+image.nwb    5.2 MB   5.2 MB           100%    ok    done                      \n",
      "000207/sub-10/sub-10_ses-10_ecephys+image.nwb 1.5 MB   1.5 MB           100%    ok    done                      \n",
      "000207/sub-18/sub-18_ses-18_ecephys+image.nwb 3.5 MB   3.5 MB           100%    ok    done                      \n",
      "000207/sub-13/sub-13_ses-13_ecephys+image.nwb 2.2 MB   2.2 MB           100%    ok    done                      \n",
      "000207/sub-14/sub-14_ses-14_ecephys+image.nwb 2.9 MB   2.9 MB           100%    ok    done                      \n",
      "000207/sub-12/sub-12_ses-12_ecephys+image.nwb 2.5 MB   2.5 MB           100%    ok    done                      \n",
      "000207/sub-15/sub-15_ses-15_ecephys+image.nwb 4.9 MB   4.9 MB           100%    ok    done                      \n",
      "000207/sub-17/sub-17_ses-17_ecephys+image.nwb 4.3 MB   4.3 MB           100%    ok    done                      \n",
      "000207/sub-19/sub-19_ses-19_ecephys+image.nwb 1.7 MB   1.7 MB           100%    ok    done                      \n",
      "000207/sub-2/sub-2_ses-2_ecephys+image.nwb    2.9 MB   2.9 MB           100%    ok    done                      \n",
      "000207/sub-3/sub-3_ses-3_ecephys+image.nwb    2.1 MB   2.1 MB           100%    ok    done                      \n",
      "000207/sub-4/sub-4_ses-4_ecephys+image.nwb    2.1 MB   2.1 MB           100%    ok    done                      \n",
      "000207/sub-6/sub-6_ses-6_ecephys+image.nwb    1.4 MB   1.4 MB           100%    ok    done                      \n",
      "000207/sub-9/sub-9_ses-9_ecephys+image.nwb    2.0 MB   2.0 MB           100%    ok    done                      \n",
      "000207/sub-8/sub-8_ses-8_ecephys+image.nwb    3.0 MB   3.0 MB           100%    ok    done                      \n",
      "000207/sub-5/sub-5_ses-5_ecephys+image.nwb    1.8 MB   1.8 MB           100%    ok    done                      \n",
      "000207/sub-7/sub-7_ses-7_ecephys+image.nwb    2.4 MB   2.4 MB           100%    ok    done                      \n",
      "Summary:                                      50.3 MB  50.3 MB                        20 done         1 updated \n",
      "                                                       100.00%                                                  \n"
     ]
    }
   ],
   "source": [
    "if not DATA_DIR.exists():\n",
    "    DATA_DIR.mkdir(parents=True)\n",
    "    dandi_download(\"DANDI:000207/0.220216.0323\", output_dir=DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ed3aa0-77f3-47b1-867c-e6acb654c0e7",
   "metadata": {},
   "source": [
    "It looks like that the data is downloaded under `000207` directory in the data directory I specified, and there are 19 subdirectories for each participant.\n",
    "Let's prepare a convenient function for reading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b960ec5-d770-4d0c-9a4b-f2f9ea3fbe60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_nwb(session_id: int) -> pynwb.NWBFile:\n",
    "    \"\"\"Load an NWB file. session_id should be an integer from 1 to 19.\"\"\"\n",
    "    path = DATA_DIR.joinpath(\n",
    "        f\"000207/sub-{session_id}/sub-{session_id}_ses-{session_id}_ecephys+image.nwb\"\n",
    "    )\n",
    "    return pynwb.NWBHDF5IO(path, mode=\"r\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbcb432-5717-4e23-9651-e400685a0139",
   "metadata": {},
   "source": [
    "While I already roughly read the paper, I have no idea what these files contain. \n",
    "To help me check the data content, NWB provides a separated package called [nwbwidgets](https://nwb-overview.readthedocs.io/en/latest/tools/nwbwidgets/nwbwidgets.html) that creates an interactive [Jupyter Widgets](https://ipywidgets.readthedocs.io/en/stable/).\n",
    "Let's load a data and visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7a8ffe2-32f3-4064-abd9-56a0a8d45900",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuji/Documents/rlog2/.venv/lib/python3.11/site-packages/pynwb/core.py:47: UserWarning: OpticalSeries 'StimulusPresentation_encoding': The number of frame indices in 'starting_frame' should have the same length as 'external_file'.\n",
      "  warn(error_msg)\n",
      "/home/yuji/Documents/rlog2/.venv/lib/python3.11/site-packages/pynwb/core.py:47: UserWarning: OpticalSeries 'StimulusPresentation_encoding': Either external_file or data must be specified (not None), but not both.\n",
      "  warn(error_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee0189be3cf4931bb4e8b8dd7b9f35c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='session_description:', layout=Layout(max_height='40px', max_width='â€¦"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "nwb10 = load_nwb(10)\n",
    "nwb2widget(nwb10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cb511c-d34a-45c6-84df-2d4466b285da",
   "metadata": {},
   "source": [
    "It didn't helped me understand the data much..., but at least, I now know that `units/Session Raster` shows me a raster plot of the spiking data. So, how can I analyze these data? And, how can I get the raw array of spikes? Let's just print out the `units`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d30ecd22-7348-4166-8e9f-bf2e0c14bcac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "units pynwb.misc.Units at 0x140382092456016\n",
       "Fields:\n",
       "  colnames: ['spike_times' 'electrodes']\n",
       "  columns: (\n",
       "    spike_times_index <class 'hdmf.common.table.VectorIndex'>,\n",
       "    spike_times <class 'hdmf.common.table.VectorData'>,\n",
       "    electrodes <class 'hdmf.common.table.DynamicTableRegion'>\n",
       "  )\n",
       "  description: units table\n",
       "  id: id <class 'hdmf.common.table.ElementIdentifiers'>\n",
       "  waveform_unit: volts"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nwb10.units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23f50dc-f2fd-4cc7-9450-80f37393e630",
   "metadata": {},
   "source": [
    "I found that it is an instance of [`Units`](https://pynwb.readthedocs.io/en/stable/pynwb.misc.html) class, which represents event times of observed units. It provides us a convenient method `get_unit_spike_times(unit: int | Sequence[int])`, which returns a `NumPy` array represents the spike timing of given a unit of units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e87909eb-cf34-411b-b7f6-beb3b01546de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.57545000e-02, 2.23144750e-01, 6.55594500e-01, ...,\n",
       "       2.88324675e+03, 2.88364036e+03, 2.88391571e+03])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nwb10.units.get_unit_spike_times(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57d8b2d-f3c7-4899-b041-bbd42b42d12a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Or, we can just access contents by `units[\"spike_times\"][unit]`. \n",
    "\n",
    "# Visualize the spikes\n",
    "\n",
    "I found a nice example of plotting it in the [pynwb document](https://pynwb.readthedocs.io/en/stable/tutorials/general/read_basics.html#visualize-spiking-activity-relative-to-stimulus-onset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04bd9518-052c-4a11-8ea5-42b511f03339",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = 1.0  # in seconds\n",
    "after = 3.0\n",
    "\n",
    "def plot_spikes(units: list[int]) -> None:\n",
    "    for unit in range(3):\n",
    "        unit_spike_times = nwbfile.units[\"spike_times\"][unit]\n",
    "        trial_spikes = []\n",
    "        for time in stim_on_times:\n",
    "            # Compute spike times relative to stimulus onset\n",
    "            aligned_spikes = unit_spike_times - time\n",
    "            # Keep only spike times in a given time window around the stimulus onset\n",
    "            aligned_spikes = aligned_spikes[\n",
    "                (-before < aligned_spikes) & (aligned_spikes < after)\n",
    "            ]\n",
    "            trial_spikes.append(aligned_spikes)\n",
    "        fig, axs = plt.subplots(2, 1, sharex=\"all\")\n",
    "        plt.xlabel(\"time (s)\")\n",
    "        axs[0].eventplot(trial_spikes)\n",
    "\n",
    "        axs[0].set_ylabel(\"trial\")\n",
    "        axs[0].set_title(\"unit {}\".format(unit))\n",
    "        axs[0].axvline(0, color=[0.5, 0.5, 0.5])\n",
    "\n",
    "        axs[1].hist(np.hstack(trial_spikes), 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c8d7649-3263-4878-94ca-16faa0a26d16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.57545000e-02, 2.23144750e-01, 6.55594500e-01, ...,\n",
       "       2.88324675e+03, 2.88364036e+03, 2.88391571e+03])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nwb10.units[\"spike_times\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e7f5f6-1025-4a44-a5a0-473fc711afb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508de60d-8c26-41ef-b099-04250a983c84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlog2",
   "language": "python",
   "name": "rlog2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
